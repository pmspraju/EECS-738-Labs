{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages Loaded\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import cifar100, cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "print(\"Packages Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import Cifar-10 data and process it.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import Cifar-100 data and process it.\n",
    "(, t), (, ) = cifar100.load_data()\n",
    "# Fill in the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our baseline model for this lab.\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, activation='relu', input_shape=(3072,)))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Notice that you can reshape the data for an MLP inside the fit call without changing it globally!\n",
    "model.fit(x_train.reshape(50000, 3072), y_train, epochs=20, batch_size=64, validation_data=(x_test.reshape(10000, 3072), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for CIFAR-100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CIFAR-10 CNN baseline here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CIFAR-100 CNN baseline here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Convolutional layers to 64 filters for CIFAR-10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Convolutional layers to 16 filters for CIFAR-10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Max Pooling Layers for CIFAR-10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Max Pooling Layers for CIFAR-100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 782 steps, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "782/782 [==============================] - 97s 124ms/step - loss: 1.8367 - accuracy: 0.3264 - val_loss: 1.3982 - val_accuracy: 0.4920\n",
      "Epoch 2/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 1.4202 - accuracy: 0.4860 - val_loss: 1.1817 - val_accuracy: 0.5753\n",
      "Epoch 3/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 1.2574 - accuracy: 0.5479 - val_loss: 1.0560 - val_accuracy: 0.6257\n",
      "Epoch 4/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 1.1465 - accuracy: 0.5897 - val_loss: 1.0090 - val_accuracy: 0.6400\n",
      "Epoch 5/40\n",
      "782/782 [==============================] - 101s 129ms/step - loss: 1.0788 - accuracy: 0.6171 - val_loss: 0.8934 - val_accuracy: 0.6844\n",
      "Epoch 6/40\n",
      "782/782 [==============================] - 96s 122ms/step - loss: 1.0210 - accuracy: 0.6411 - val_loss: 0.9206 - val_accuracy: 0.6845\n",
      "Epoch 7/40\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.9729 - accuracy: 0.6567 - val_loss: 0.8445 - val_accuracy: 0.7056\n",
      "Epoch 8/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.9255 - accuracy: 0.6709 - val_loss: 0.8137 - val_accuracy: 0.7244\n",
      "Epoch 9/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.8906 - accuracy: 0.6871 - val_loss: 0.7845 - val_accuracy: 0.7278\n",
      "Epoch 10/40\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.8680 - accuracy: 0.6975 - val_loss: 0.7315 - val_accuracy: 0.7473\n",
      "Epoch 11/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.8390 - accuracy: 0.7057 - val_loss: 0.7410 - val_accuracy: 0.7430\n",
      "Epoch 12/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.8199 - accuracy: 0.7134 - val_loss: 0.7189 - val_accuracy: 0.7539\n",
      "Epoch 13/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.8041 - accuracy: 0.7187 - val_loss: 0.6889 - val_accuracy: 0.7559\n",
      "Epoch 14/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.7907 - accuracy: 0.7232 - val_loss: 0.7036 - val_accuracy: 0.7570\n",
      "Epoch 15/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.7733 - accuracy: 0.7301 - val_loss: 0.6961 - val_accuracy: 0.7639\n",
      "Epoch 16/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.7577 - accuracy: 0.7360 - val_loss: 0.6755 - val_accuracy: 0.7665\n",
      "Epoch 17/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.7481 - accuracy: 0.7396 - val_loss: 0.6707 - val_accuracy: 0.7697\n",
      "Epoch 18/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.7404 - accuracy: 0.7428 - val_loss: 0.6921 - val_accuracy: 0.7626\n",
      "Epoch 19/40\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.7260 - accuracy: 0.7470 - val_loss: 0.6605 - val_accuracy: 0.7725\n",
      "Epoch 20/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.7199 - accuracy: 0.7474 - val_loss: 0.6993 - val_accuracy: 0.7702\n",
      "Epoch 21/40\n",
      "782/782 [==============================] - 96s 122ms/step - loss: 0.7055 - accuracy: 0.7546 - val_loss: 0.6479 - val_accuracy: 0.7813\n",
      "Epoch 22/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.7063 - accuracy: 0.7553 - val_loss: 0.6354 - val_accuracy: 0.7849\n",
      "Epoch 23/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6957 - accuracy: 0.7588 - val_loss: 0.6297 - val_accuracy: 0.7914\n",
      "Epoch 24/40\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.6875 - accuracy: 0.7617 - val_loss: 0.6182 - val_accuracy: 0.7890\n",
      "Epoch 25/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6874 - accuracy: 0.7618 - val_loss: 0.6430 - val_accuracy: 0.7819\n",
      "Epoch 26/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6854 - accuracy: 0.7634 - val_loss: 0.6539 - val_accuracy: 0.7850\n",
      "Epoch 27/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6673 - accuracy: 0.7681 - val_loss: 0.6345 - val_accuracy: 0.7842\n",
      "Epoch 28/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6679 - accuracy: 0.7682 - val_loss: 0.6640 - val_accuracy: 0.7793\n",
      "Epoch 29/40\n",
      "782/782 [==============================] - 95s 122ms/step - loss: 0.6635 - accuracy: 0.7710 - val_loss: 0.6248 - val_accuracy: 0.7853\n",
      "Epoch 30/40\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.6569 - accuracy: 0.7704 - val_loss: 0.5951 - val_accuracy: 0.8004\n",
      "Epoch 31/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6529 - accuracy: 0.7743 - val_loss: 0.6019 - val_accuracy: 0.7941\n",
      "Epoch 32/40\n",
      "782/782 [==============================] - 94s 121ms/step - loss: 0.6504 - accuracy: 0.7753 - val_loss: 0.5859 - val_accuracy: 0.8023\n",
      "Epoch 33/40\n",
      "782/782 [==============================] - 97s 124ms/step - loss: 0.6357 - accuracy: 0.7789 - val_loss: 0.6280 - val_accuracy: 0.7883\n",
      "Epoch 34/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6389 - accuracy: 0.7776 - val_loss: 0.5808 - val_accuracy: 0.8025\n",
      "Epoch 35/40\n",
      "782/782 [==============================] - 95s 121ms/step - loss: 0.6341 - accuracy: 0.7794 - val_loss: 0.6062 - val_accuracy: 0.7993\n",
      "Epoch 36/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6284 - accuracy: 0.7820 - val_loss: 0.5900 - val_accuracy: 0.8021\n",
      "Epoch 37/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6234 - accuracy: 0.7864 - val_loss: 0.5830 - val_accuracy: 0.8073\n",
      "Epoch 38/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6207 - accuracy: 0.7839 - val_loss: 0.5917 - val_accuracy: 0.8010\n",
      "Epoch 39/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6223 - accuracy: 0.7854 - val_loss: 0.5780 - val_accuracy: 0.8069\n",
      "Epoch 40/40\n",
      "782/782 [==============================] - 94s 120ms/step - loss: 0.6154 - accuracy: 0.7872 - val_loss: 0.6042 - val_accuracy: 0.7946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22e8a7b1508>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Augmentation.\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 40\n",
    "data_augmentation = True\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False,\n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        zca_epsilon=1e-06,\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0., \n",
    "        zoom_range=0., \n",
    "        channel_shift_range=0.,\n",
    "        fill_mode='nearest',\n",
    "        cval=0., \n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False, \n",
    "        rescale=None,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0)\n",
    "\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    model.fit(datagen.flow(x_train, y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test))\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is our CIFAR-10 CNN ResNet.\n",
    "inputs = tf.keras.Input(shape=(32, 32, 3), name='img')\n",
    "x = Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = Conv2D(64, 3, activation='relu')(x)\n",
    "block_1_output = MaxPooling2D(3)(x)\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_1_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_2_output = tf.keras.layers.add([x, block_1_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_2_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_3_output = tf.keras.layers.add([x, block_2_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_3_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_4_output = tf.keras.layers.add([x, block_3_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_4_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_5_output = tf.keras.layers.add([x, block_4_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_5_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_6_output = tf.keras.layers.add([x, block_5_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_6_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_7_output = tf.keras.layers.add([x, block_6_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_7_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_8_output = tf.keras.layers.add([x, block_7_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_8_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_9_output = tf.keras.layers.add([x, block_8_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_9_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_10_output = tf.keras.layers.add([x, block_9_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_10_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_11_output = tf.keras.layers.add([x, block_10_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_11_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_12_output = tf.keras.layers.add([x, block_11_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_12_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_13_output = tf.keras.layers.add([x, block_12_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_13_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_14_output = tf.keras.layers.add([x, block_13_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_14_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_15_output = tf.keras.layers.add([x, block_14_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_15_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_16_output = tf.keras.layers.add([x, block_15_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_16_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_17_output = tf.keras.layers.add([x, block_16_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_17_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_18_output = tf.keras.layers.add([x, block_17_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_18_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_19_output = tf.keras.layers.add([x, block_18_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(block_19_output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "block_20_output = tf.keras.layers.add([x, block_19_output])\n",
    "\n",
    "x = Conv2D(64, 3, activation='relu')(block_20_output)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs, name='resnet')\n",
    "\n",
    "\n",
    "model.compile(Adam(amsgrad=True), 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=256,\n",
    "          epochs=10,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CIFAR-100 CNN ResNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your own CNN that rivals a CNN ResNet for CIFAR-100.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
